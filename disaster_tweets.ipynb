{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
      "1                Forest fire near La Ronge Sask. Canada       1  \n",
      "2     All residents asked to 'shelter in place' are ...       1  \n",
      "3     13,000 people receive #wildfires evacuation or...       1  \n",
      "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
      "7611  Police investigating after an e-bike collided ...       1  \n",
      "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
      "\n",
      "[7613 rows x 5 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mague\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mague\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Descargar recursos de NLTK si no están disponibles\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "train_file = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(train_file)\n",
    "\n",
    "# Información básica del dataset\n",
    "print(train_file.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Our Deeds are the Reason of this #earthquake M...   \n",
      "1             Forest fire near La Ronge Sask. Canada   \n",
      "2  All residents asked to 'shelter in place' are ...   \n",
      "3  13,000 people receive #wildfires evacuation or...   \n",
      "4  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "                                          clean_text  \n",
      "0       deeds reason earthquake may allah forgive us  \n",
      "1              forest fire near la ronge sask canada  \n",
      "2  residents asked shelter place notified officer...  \n",
      "3  people receive wildfires evacuation orders cal...  \n",
      "4  got sent photo ruby alaska smoke wildfires pou...  \n"
     ]
    }
   ],
   "source": [
    "# Función para limpiar el texto de los tweets\n",
    "def clean_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Quitar URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    # Quitar caracteres especiales y puntuación\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenización\n",
    "    words = word_tokenize(text)\n",
    "    # Quitar stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_text = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(cleaned_text)\n",
    "\n",
    "# Aplicar la función de limpieza a la columna de texto\n",
    "train_file['clean_text'] = train_file['text'].apply(clean_text)\n",
    "\n",
    "# Mostrar las primeras filas con el texto limpio\n",
    "print(train_file[['text', 'clean_text']].head())\n",
    "\n",
    "train_file.to_csv(\"train-cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Cargar los datos desde el archivo CSV\n",
    "train_file = pd.read_csv(\"train-cleaned.csv\")\n",
    "\n",
    "# Separar los tweets por categoría\n",
    "disaster_tweets = train_file[train_file['target'] == 1]\n",
    "non_disaster_tweets = train_file[train_file['target'] == 0]\n",
    "\n",
    "# Unir todos los textos en cada categoría\n",
    "all_words_disaster = ' '.join(disaster_tweets['clean_text'])\n",
    "all_words_non_disaster = ' '.join(non_disaster_tweets['clean_text'])\n",
    "\n",
    "# Crear frecuencias de palabras\n",
    "fdist_disaster = FreqDist(all_words_disaster.split())\n",
    "fdist_non_disaster = FreqDist(all_words_non_disaster.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e6622df990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, dcc, html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Datos para el gráfico de palabras más comunes en tweets de desastre\n",
    "common_words_disaster = fdist_disaster.most_common(30)\n",
    "df_disaster = pd.DataFrame(common_words_disaster, columns=['Palabra', 'Frecuencia'])\n",
    "\n",
    "# Crear el gráfico de barras para los tweets de desastre\n",
    "fig_disaster = px.bar(df_disaster, x='Palabra', y='Frecuencia', title='Frecuencia de Palabras - Tweets de Desastres')\n",
    "\n",
    "# Datos para el gráfico de palabras más comunes en tweets de no desastre\n",
    "common_words_non_disaster = fdist_non_disaster.most_common(30)\n",
    "df_non_disaster = pd.DataFrame(common_words_non_disaster, columns=['Palabra', 'Frecuencia'])\n",
    "\n",
    "# Crear el gráfico de barras para los tweets de no desastre\n",
    "fig_non_disaster = px.bar(df_non_disaster, x='Palabra', y='Frecuencia', title='Frecuencia de Palabras - Tweets de No Desastres')\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Análisis de Tweets de Desastres y No Desastres'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Frecuencia de palabras más comunes.\n",
    "    '''),\n",
    "\n",
    "    # Gráfico de palabras más comunes en tweets de desastres\n",
    "    dcc.Graph(\n",
    "        id='disaster-words',\n",
    "        figure=fig_disaster\n",
    "    ),\n",
    "\n",
    "    # Gráfico de palabras más comunes en tweets de no desastres\n",
    "    dcc.Graph(\n",
    "        id='non-disaster-words',\n",
    "        figure=fig_non_disaster\n",
    "    )\n",
    "])\n",
    "\n",
    "# Ejecutar la aplicación\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
